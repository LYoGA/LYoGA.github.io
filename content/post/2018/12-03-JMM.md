---
title: "JAVA内存模型（JMM）"
date: 2018-12-03T15:03:03+08:00
lastmod: 2018-12-03T15:03:03+08:00
draft: false
keywords:
-
description: ""
tags:
- 并发编程
- JVM
categories:
- 并发编程
- JVM
author: "lyoga"

---

<!--more-->
# **前言** #
在并发编程中，我们需要处理两个关键问题:

**线程之间如何通信及线程之间如何同步**

> 这里的线程是指并发执行的活动实体；通信是指线程之间以何种机制来交换信息

在命令式编程中，线程之间的通信机制有两种

1. 共享内存
2. 消息传递

> **共享内存并发模型：** 线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信

> **消息传递并发模型：** 线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信

**同步是指程序用于控制不同线程之间操作发生相对顺序的机制**

- 在共享内存并发模型里，同步是显式进行的，程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行；典型的共享内存通信方式就是通过共享对象进行通信
- 在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的；在java中典型的消息传递方式就是wait()和notify()

Java的并发采用的是 **共享内存模型**，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明

&nbsp;

# **一、JMM共享内存模型** #
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216162854.png)

- 线程之间的共享变量存储在主内存(main memory)中，每个线程都有一个私有的本地内存(local memory)，本地内存中存储了该线程以读/写共享变量的副本
- 不同线程通过主内存进行通信
- 主内存映射到cpu的缓存系统、内存
- 本地内存映射到cpu私有的数据结构，如寄存器、与cache之间的指令buffer

**JMM通过控制主内存与每个线程的本地内存之间的交互，为java程序员提供内存可见性保证**

&nbsp;

# **二、重排序** #
## **2.1 编译器重排序** ##
编译器(JIT)在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序，即对指令进行重排序，以提高性能

## **2.2 处理器重排序** ##
1. 指令级并行的重排序
2. 内存系统的重排序

**2.2.1 指令重排序：** 现代处理器采用了指令级并行技术(Instruction-Level Parallelism， ILP)来将多条指令重叠执行；如果不存在数据依赖性,处理器可以改变语句对应机器指令的执行顺序

比较违反直觉的Speculative Execution（预测执行）：
```
if (ready)
  b = a * a;
```
Speculative Execution允许ready的load和a*a的计算并发执行，a*a的中间结果被保存到cpu的Reorder Buffer中，当ready的load完成并为true时，再把该结果写入b中

**2.2.2 内存重排序(memory reordering)：** 由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216231210.png)
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216231052.png)

- 内存的访问是昂贵的
- Cache Coherence（高速缓存一致性）的保证是昂贵的
- 缓存一致性协议（MESI）保证一旦某个变量被flush到cache，则对所有的core可见
- 每个core私有的数据结构（load buffer、store buffer、write combine buffer）缓冲内存访问指令，以避免cpu停顿，并进行合适的重排序：
  1. 合并对同一地址的写
  2. 安排地址相近的指令一起执行
  3. 先执行命中cache的load
  4. 直接从write buffer中load数据，不访问cache
- cpu与cache/memory的交互，是异步的

## **2.3 硬件内存模型** ##

- 四种指令乱序：load-load / load-store / store-store / store-load
- 不同底层平台有各自乱序的规则，允许的乱序越多，内存模型越弱

![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216204041.png)

&nbsp;

## **2.4 什么情况下允许重排序** ##
**1.数据依赖性**

如果两个操作访问同一个变量，且这两个操作中有一个为写操作，则这两个操作存在数据依赖性,不允许重排序，否则执行结果将改变

- 写后读a = 1；b = a；写一个变量之后，再读这个位置
- 写后写a = 1；a = 2；写一个变量之后，再写这个变量
- 读后写a = b；b = 1；读一个变量之后，再写这个变量

**注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑**

**2.as-if-serial语义**

**不管怎么重排序(编译器和处理器为了提高并行度)，(单线程)程序的执行结果不能被改变，编译器、处理器都必须遵守as-if-serial语义。**

1.  as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。
2.  as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。
3.  as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。

**3.存在控制依赖的指令允许重排序**
``` java
// eg. speculative execution  
if(ready)
  print a
```

- 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果(这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因)
- 但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果

&nbsp;

## **2.5 重排序对多线程的影响** ##
**问题**
``` java
// 初始状态
a = 0;
flag = false;

// Thread 1
a = 1;
ready = true;

// Thread 2
if (ready)
  System.out.println(a); // 打印什么
```

**情况一**

- Thread 1中的两个store没有数据依赖性，允许store-store乱序
- 可能执行的顺序:
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216211424.png)
- 打印0

**情况二**

- 即使Thread 1没有重排序，Thread 2也可能因为Speculative Execution而导致load-load乱序
- 可能执行的顺序:
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216211623.png)
- 打印0

&nbsp;

## **2.6 禁止处理器重排序** ##
### **2.6.1 内存屏障(memory barrier)** ###
先简单了解两个指令：

- Store：将处理器缓存的数据刷新到内存中
- Load：将内存存储的数据拷贝到处理器的缓存中

**为了保证多线程之间内存操作的有序性、可见性，java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序**

理论上存在四种barrier，分别对应四种乱序

1. load-load barrier
2. load-store barrier
3. store-store barrier
4. store-load barrier

**这些屏障可统一用XY来表示，XY屏障的作用是禁止屏障左侧的任何X操作与屏障右侧的任何Y操作之间进行重排序**

- LoadLoad屏障：对于这样的语句 Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕
- StoreStore屏障：对于这样的语句 Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见
- LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被执行前，保证Load1要读取的数据被读取完毕
- StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见

**StoreLoad屏障开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列），在大多数处理器的实现中，这个屏障是个万能屏障(full barrier)，兼具其它三种内存屏障的功能**

**内存屏障分类**

- 按照可见性保障来划分，内存屏障可分为：**加载屏障（Load Barrier）和存储屏障（Store Barrier）**
    1. 加载屏障：StoreLoad屏障可充当加载屏障，作用是使用load原子操作，刷新处理器缓存，即清空无效化队列，使处理器在读取共享变量时，先从主内存或其他处理器的高速缓存中读取相应变量，更新到自己的缓存中
    2. 存储屏障：StoreLoad屏障可充当存储屏障，作用是使用store原子操作，冲刷处理器缓存，即将写缓冲器内容写入高速缓存中，使处理器对共享变量的更新写入高速缓存或者主内存中

**这两个屏障一起保证了数据在多处理器之间是可见的**

- 按照有序性保障来划分，内存屏障分为：**获取屏障（Acquire Barrier）和释放屏障（Release Barrier）**
    1. 获取屏障：相当于LoadLoad屏障与LoadStore屏障的组合。在读操作后插入，禁止该读操作与其后的任何读写操作发生重排序；
    2. 释放屏障：相当于LoadStore屏障与StoreStore屏障的组合。在一个写操作之前插入，禁止该写操作与其前面的任何读写操作发生重排序。

**这两个屏障一起保证了临界区中的任何读写操作不可能被重排序到临界区之外**

**如图：**
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216224326.png)

&nbsp;

**从 java 源代码到最终实际执行的指令序列,会分别经历下面三种重排序:**
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216201709.png)

- 对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序(不是所有的编译器重排序都要禁止)
- 对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障(memory barriers，intel称之为memory fence)指令，通过内存屏障指令来禁止特定类型的处理器重排序(不是所有的处理器重排序都要禁止)

&nbsp;

**JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。**

&nbsp;

# **三、顺序一致性** #
## **3.1 数据竞争与顺序一致性保证** ##
当程序未正确同步时，就可能会存在数据竞争

**java内存模型规范对数据竞争的定义如下:**

- 在一个线程中写一个变量
- 在另一个线程读同一个变量
- 而且写和读没有通过同步来排序

当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果；如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。

**JMM 对正确同步的多线程程序的内存一致性做了如下保证:**

1. 如果程序是正确同步的,程序的执行将具有顺序一致性(sequentially consistent)，即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同
2. 这对于程序员来说是一个极强的保证。这里的同步是指广义上的同步，包括对常用同步原语(synchronized，volatile，final) 的正确使用

&nbsp;

## **3.2 顺序一致性内存模型** ##
**顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证**

**顺序一致性内存模型有两大特性:**

- 一个线程中的所有操作必须按照程序的顺序来执行
- （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序；在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见

**顺序一致性内存模型为程序员提供的视图如下:**
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181217194150.png)

1. 在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程，同时每一个线程必须按照程序的顺序来执行内存读/写操作
2. 从上面的示意图我们可以看出，在任意时间点最多只能有一个线程可以连接到内存；
3. 当多个线程并发执行时，图中的开关装置能把所有线程的所有内存读/写操作串行化(即在顺序一致性模型中，所有操作之间具有全序关系)

&nbsp;

假设两个线程A、B并发执行，其中A线程有3个操作，它们在程序中的顺序是：A1-A2-A3；其中B线程也有3个操作，它们在程序中的顺序是：B1-B2-B3

&nbsp;

**假设两个线程使用监视器锁来正确同步:**
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181217201154.png)

&nbsp;

**假设这两个线程没有做同步：**
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181217201227.png)

1. 未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。
2. 以上图为例，线程A和B看到的执行顺序都是:B1->A1->A2->B2->A3->B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。
3. 在JMM中就没有这个保证；未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致

&nbsp;

## **3.3 同步程序的顺序一致性效果** ##
```java
class SynchronizedExample {
  int a = 0;
  boolean flag = false;

  public synchronized void writer() {
    a = 1;
    flag = true;
  }

  public synchronized void reader() { //获取锁
    if (flag) {
      int i = a;
    }
  }
}
```
上面示例代码中，假设A线程执行writer()方法后，B线程执行reader()方法。这是一个正确同步的多线程程序。根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。

**下面是该程序在两个内存模型中的执行时序对比图:**
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181217195543.png)

1. 在顺序一致性模型中，所有操作完全按程序的顺序串行执行
2. 在JMM中，临界区内的代码可以重排序(但JMM不允许临界区内的代码“逸出”到临界区之外,，那样会破坏监视器的语义)
3. JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图
4. 虽然线程A在临界区内做了重排序，但由于监视器的互斥执行的特性，这里的线程B根本无法“观察”到线程A在临界区内的重排序，这种重排序既提高了执行效率,又没有改变程序的执行结果

&nbsp;

## **3.4 顺序一致性模型与JMM的区别** ##
**对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值(0，null，false)，JMM保证线程读操作读取到的值不会无中生有(out of thin air)**

**未同步程序在两个模型中的执行特性差异：**

1. 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单线程内的操作会按程序的顺序执行。（比如正确同步的多线程程序在临界区内的重排序）
2. 顺序一致性模型保证所有线程能看到一致的操作执行顺序，而JMM不保证所有线程能看到一致的操作执行顺序。
3. JMM不保证对64位long型和double型变量的写操作具有原子性，而顺序一致性模型能保证对所有的内存读/写操作都具有原子性。

&nbsp;

# **四、volatile** #
## **4.1 特性：** ##

- 可见性：对一个 volatile变量的读，总是能看到(任意线程)对这个volatile变量最后的写入。
- 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。
- 有序性：禁止重排序（包括编译器重排和处理器重排）

## **4.2 volatile的内存语义** ##
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181219210032.png)

为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序;对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此JMM采取保守策略

![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181219210834.png)

> eg：X86处理器不会对读-读，读-写和写-写操作做重排序，因此会省略掉这三种操作类型对应的内存屏障。在x86中，JMM仅需在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义

![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181219232827.png)

&nbsp;

# **五、synchronized** #
## **5.1 特性：** ##

- 可见性
- 原子性
- 有序性

## **5.2 内存语义：** ##
![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181219210032.png)

**synchronized编译成字节码后，是通过monitorenter（入锁）和monitorexit（出锁）两个指令实现的，如图：**

![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181220114234.png)

**synchronized底层也是通过释放屏障和获取屏障的配对使用保障有序性，加载屏障和存储屏障的配对使用保障可见性。最后又通过锁的排他性保障了原子性**

&nbsp;

# **六、final内存语义** #
假设x是一个对象，内部有一个final字段finalField，那么：

- x构造函数内对finalField的写，与后续把x赋给另一个引用变量，不可重排序

  >  - x.finalField = v;sharedRef = x;
  >  - 在finalFiled的store后放一个StoreStore barrier即可

- 初次读x，和初次读x.finalField，不可重排序（处理器）

   > - x = sharedRef;i = x.finalField;
   > - 在finalField的load前放一个LoadLoad barrier即可

- 目的是要保证：当其他线程看到x时，finalField肯定已经正确初始化了
- x86平台不允许出现StoreStore/LoadLoad乱序，因此finalField的读写不会插入任何memory barrier

&nbsp;

# **七、happens-before** #
从JDK5开始，Java使用新的JSR-133内存模型。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。

- 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系
  - eg：A happens-before B，意味着A对内存的影响，对B是可见的（AB可能在单线程中，也可能在不同线程之间）
- 与程序员密切相关的happens-before规则如下(JMM提供的"幻境"):
  1. 程序顺序规则:一个线程中的每个操作，happens-before于该线程中的任意后续操作
  2. 监视器锁规则:对一个监视器的解锁，happens-before于随后对这个监视器的加锁
  3. volatile变量规则:对一个volatile域的写，happens-before于任意后续对这个volatile域的读
  4. 传递性:如果 A happens-before B,且 B happens-before C,那么 A happens-before C
  5. start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作
  6. join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回

&nbsp;

![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216194624.png)

- 单线程内，1 happens-before 2，3 happens-before 4
  - （as-if-serial语义）
- 由volatile的happens-before规则可知，2 happens-before 3
  - （volatile store 后插入的full barrier）
- 由传递性，1 happens-before 3，1 happens-before 4，即线程二执行到3和4时，肯定可以看到线程一对a的赋值1
  - （volatile的read-acquire / write-release语义）

&nbsp;

**happens-before与JMM的关系如下图所示:**

![](https://lyoga-1257336739.cos.ap-beijing.myqcloud.com/20181216194401.png)

- 如上图所示,一个happens-before规则对应于一个或多个编译器和处理器重排序规则
- 对于java程序员来说，happens-before规则简单易懂，它避免java程序员为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现

&nbsp;

# **参考** #

- http://ifeve.com/java-memory-model-0/
- https://tech.meituan.com/java_memory_reordering.html
- https://www.jianshu.com/p/7d3150fc0277
- http://www.sohu.com/a/250012524_467784
- http://www.cnblogs.com/lemos/p/9252342.html
